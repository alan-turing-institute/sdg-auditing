{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e792f55",
   "metadata": {},
   "source": [
    "## Use Case 2\n",
    "\n",
    "A multinomial regression of approximated Social Grade on Ethnic Group, Country of Birth and Family Composition, i.e. considering these four variables. In this way we could constructive a narrative around use case 1 being focussed on some economic variables/analyses, use case 2 on socio-demographic variables/analyses and use case 3 a broad analysis primarily to test performance of the methods in protecting privacy and preserving utility.\n",
    "\n",
    "(This notebook uses the same structure as the other use case notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572ebf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tqdm\n",
    "import tqdm.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21065aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads of warnings coming from the sub-methods, which we don't care about.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4645eab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 15:58:47.925762: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from utils import load_data, load_synthetic_datasets, metadata, custom_ipf, custom_mst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bff082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc91b29f",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f14a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "teaching_file_train = load_data(train=True, test=False)\n",
    "teaching_file_test = load_data(train=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc7c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = len(teaching_file_train) + len(teaching_file_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b434906f",
   "metadata": {},
   "source": [
    "### Use case "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3eab25",
   "metadata": {},
   "source": [
    "What columns are used in the task? What marginals should be preserved for this task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e3c0320",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Ethnic Group\", \"Country of Birth\", \"Family Composition\", \"Approximated Social Grade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a0c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoric = columns[:-1]\n",
    "target = columns[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8ea38",
   "metadata": {},
   "source": [
    "We use 3-way marginals for the demographics, and 2-ways with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81da086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_marginals = [(0, 1, 2), (0, 3), (1, 3), (2, 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914427f",
   "metadata": {},
   "source": [
    "Process the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03a34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = teaching_file_test.copy()\n",
    "X_test_df, y_test_df = df.drop(target, axis=1), df[target]\n",
    "X_test_df[categoric] = X_test_df[categoric].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdcee74",
   "metadata": {},
   "source": [
    "Define the task of interest (analysis on data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c136d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(dataset, split_to_estimate_accuracy=True):    \n",
    "    # Get the categories from the metadata.\n",
    "    categories = {m[\"name\"]: m[\"representation\"] for m in metadata if m[\"name\"] in categoric}\n",
    "    \n",
    "    # Define the encoder and model (random forest with default parameters).\n",
    "    encoder = OneHotEncoder(categories=[categories[m] for m in categoric])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            (\"encode\", encoder, categoric),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "    logreg = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "    pipe = Pipeline([(\"preprocess\", preprocessor), (\"model\", logreg)])\n",
    "    \n",
    "    # Load the dataset, divide into train/test (to evaluate).\n",
    "    df = dataset[columns].copy()\n",
    "    X, y = df.drop(target, axis=1), df[target]\n",
    "    X[categoric] = X[categoric].astype(str)\n",
    "    \n",
    "    if split_to_estimate_accuracy:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify=y)\n",
    "    else:\n",
    "        X_train = X\n",
    "        y_train = y\n",
    "        X_test = X_test_df\n",
    "        y_test = y_test_df\n",
    "    \n",
    "    # Apply the pipeline, and do predictions on the test set.\n",
    "    model = pipe.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Return the model + the y_pred/y_true to evaluate.\n",
    "    return (model, y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd1bc5",
   "metadata": {},
   "source": [
    "Define how to measure the success of this analysis (how close it is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "235e2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility(task_output_synth):\n",
    "    # Get the model and samples to estimate the accuracy.\n",
    "    categoric = columns[:-1]\n",
    "    target = columns[-1]\n",
    "    model, y_pred_est, y_test_est = task_output_synth\n",
    "\n",
    "    # Evaluate the accuracy of the model trained on synthetic data.\n",
    "    y_real_est = model.predict(X_test_df).astype(str)\n",
    "    real_accuracy = accuracy_score(y_test_df, y_real_est)\n",
    "    estimated_accuracy = accuracy_score(y_test_est, y_pred_est)\n",
    "    return real_accuracy, estimated_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d434d",
   "metadata": {},
   "source": [
    "### Generating tailored datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f08a14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_seed = 42387342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88c54423",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37bf62e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(master_seed)\n",
    "seeds = np.random.randint(np.iinfo(np.int16).max, size=num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c060acf6",
   "metadata": {},
   "source": [
    "IPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fe1e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    custom_ipf(teaching_file_train, columns, \"use_case_2_ipf\", seed, acceptable_marginals, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0109b17f",
   "metadata": {},
   "source": [
    "MST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bdf7a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    custom_mst(teaching_file_train, columns, \"use_case_2_mst\", seed, acceptable_marginals, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b576fb",
   "metadata": {},
   "source": [
    "### Loading synthetic datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6647bf73",
   "metadata": {},
   "source": [
    "Load generated datasets that are agnostic to the task, as well as the datasets from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a5195cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\n",
    "    \"use_case_2_ipf\",\n",
    "    \"use_case_2_mst\",\n",
    "    \"MST_eps1000\",\n",
    "    \"CTGAN_10epochs\",\n",
    "    \"PATEGAN_eps1000\",\n",
    "    \"PrivBayes_eps1000\",\n",
    "    \"SYNTHPOP\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec673c9",
   "metadata": {},
   "source": [
    "### Summarising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "097e0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_datasets = load_synthetic_datasets(methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf7cc5",
   "metadata": {},
   "source": [
    "Save these task results to disk to remove the need for repeated expensive computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23f68062",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"use_case_2.pickle\", \"rb\") as ff:\n",
    "        task_real_data, results = pickle.load(ff)\n",
    "except Exception as err:\n",
    "    task_real_data = task(teaching_file_train, split_to_estimate_accuracy=False)\n",
    "    results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cc3d48",
   "metadata": {},
   "source": [
    "The following is re-entrant: pre-existing results will not be recomputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c87d4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16947ac082e4e5086dc6f7cd4c35504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_case_2_ipf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_case_2_mst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for method in tqdm.notebook.tqdm(methods):\n",
    "    # Prevent re-computation of the task.\n",
    "    if method in results and len(results[method]) == len(synthetic_datasets[method]):\n",
    "        continue\n",
    "    print(method)\n",
    "    results[method] = L = []\n",
    "    for ds in synthetic_datasets[method]:\n",
    "        L.append(task(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5972b9",
   "metadata": {},
   "source": [
    "Conversely, load these results! You may start here when running the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83d206d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"use_case_2.pickle\", \"wb\") as ff:\n",
    "    pickle.dump((task_real_data, results), ff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8d967",
   "metadata": {},
   "source": [
    "Print the accuracy of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a31a12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy trained on _real_ data: 0.3411671785870996\n",
      "\n",
      "=== use_case_2_ipf ===\n",
      "\t Accuracy of classifier:   0.3410794207985959\n",
      "\t Accuracy estimated on SD: 0.3407045971524053\n",
      "\n",
      "=== use_case_2_mst ===\n",
      "\t Accuracy of classifier:   0.3410899517332163\n",
      "\t Accuracy estimated on SD: 0.34018366143390716\n",
      "\n",
      "=== MST_eps1000 ===\n",
      "\t Accuracy of classifier:   0.3118946906537955\n",
      "\t Accuracy estimated on SD: 0.2968645567131905\n",
      "\n",
      "=== CTGAN_10epochs ===\n",
      "\t Accuracy of classifier:   0.2881228609039052\n",
      "\t Accuracy estimated on SD: 0.3799868010896122\n",
      "\n",
      "=== PATEGAN_eps1000 ===\n",
      "\t Accuracy of classifier:   0.20524089512944274\n",
      "\t Accuracy estimated on SD: 0.4034162711674014\n",
      "\n",
      "=== PrivBayes_eps1000 ===\n",
      "\t Accuracy of classifier:   0.31195085563843794\n",
      "\t Accuracy estimated on SD: 0.3060897525906372\n",
      "\n",
      "=== SYNTHPOP ===\n",
      "\t Accuracy of classifier:   0.3410408073716542\n",
      "\t Accuracy estimated on SD: 0.34035075402285936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy trained on _real_ data:\", accuracy_score(task_real_data[1], task_real_data[2]))\n",
    "print()\n",
    "\n",
    "for method in methods:\n",
    "    print('===', method, '===')\n",
    "    acc_method_real = 0\n",
    "    acc_method_est = 0\n",
    "    for task_result in results[method]:\n",
    "        ar, ae = utility(task_result)\n",
    "        acc_method_real += ar\n",
    "        acc_method_est += ae\n",
    "    print('\\t Accuracy of classifier:  ', acc_method_real / len(results[method]))\n",
    "    print('\\t Accuracy estimated on SD:', acc_method_est / len(results[method]))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
