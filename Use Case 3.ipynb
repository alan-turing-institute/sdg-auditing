{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d5244b",
   "metadata": {},
   "source": [
    "## Use Case 3\n",
    "\n",
    "Train a random forest to predict \"Health\" from \"Hours worked per week\", \"Age\", \"Marital Status\", \"Occupation\", \"Industry\", \"Region\".\n",
    "\n",
    "(This notebook uses the same structure as the other use case notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572ebf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tqdm\n",
    "import tqdm.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bff082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21065aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads of warnings coming from the sub-methods, which we don't care about.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4645eab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 16:17:11.822978: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from utils import load_data, load_synthetic_datasets, metadata, custom_ipf, custom_mst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc91b29f",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f14a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "teaching_file_train = load_data(train=True, test=False)\n",
    "teaching_file_test = load_data(train=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed509f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = len(teaching_file_train) + len(teaching_file_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b434906f",
   "metadata": {},
   "source": [
    "### Use case "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3eab25",
   "metadata": {},
   "source": [
    "What columns are used in the task? What marginals should be preserved for this task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e3c0320",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Marital Status\", \"Occupation\", \"Industry\", \"Region\", \"Hours worked per week\", \"Age\", \"Health\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81da086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: use all 2-way marginals.\n",
    "num_columns = len(columns)\n",
    "\n",
    "acceptable_marginals = list(itertools.combinations(range(num_columns), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4623025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Marital Status', 'Occupation'],\n",
       " ['Marital Status', 'Industry'],\n",
       " ['Marital Status', 'Region'],\n",
       " ['Marital Status', 'Hours worked per week'],\n",
       " ['Marital Status', 'Age'],\n",
       " ['Marital Status', 'Health'],\n",
       " ['Occupation', 'Industry'],\n",
       " ['Occupation', 'Region'],\n",
       " ['Occupation', 'Hours worked per week'],\n",
       " ['Occupation', 'Age'],\n",
       " ['Occupation', 'Health'],\n",
       " ['Industry', 'Region'],\n",
       " ['Industry', 'Hours worked per week'],\n",
       " ['Industry', 'Age'],\n",
       " ['Industry', 'Health'],\n",
       " ['Region', 'Hours worked per week'],\n",
       " ['Region', 'Age'],\n",
       " ['Region', 'Health'],\n",
       " ['Hours worked per week', 'Age'],\n",
       " ['Hours worked per week', 'Health'],\n",
       " ['Age', 'Health']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[columns[i] for i in c] for c in acceptable_marginals]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdcee74",
   "metadata": {},
   "source": [
    "Define the task of interest (analysis on data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb35fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = [\"Hours worked per week\", \"Age\"]\n",
    "categoric = [\"Marital Status\", \"Occupation\", \"Industry\", \"Region\"]\n",
    "target = \"Health\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2507a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the test file in the same format.\n",
    "df = teaching_file_test.copy()\n",
    "df = df[[*numeric, *categoric, target]].dropna()\n",
    "\n",
    "X_test_df, y_test_df = df.drop(target, axis=1), df[target]\n",
    "X_test_df[numeric] = X_test_df[numeric].astype(int)\n",
    "X_test_df[categoric] = X_test_df[categoric].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c136d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(dataset, split_to_estimate_accuracy = True):\n",
    "    # Get the categories from the metadata.\n",
    "    categories = {m[\"name\"]: m[\"representation\"] for m in metadata if m[\"name\"] in categoric}\n",
    "    \n",
    "    # Define the encoder and model (random forest with default parameters).\n",
    "    encoder = OneHotEncoder(categories=[categories[m] for m in categoric])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            (\"encode\", encoder, categoric),\n",
    "            (\"rescale\", StandardScaler(), numeric)\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "    forest = RandomForestClassifier(\n",
    "        random_state=0, n_jobs=-1, class_weight=\"balanced_subsample\"\n",
    "    )\n",
    "    pipe = Pipeline([(\"preprocess\", preprocessor), (\"model\", forest)])\n",
    "    \n",
    "    # Load the dataset, divide into train/test (to evaluate).\n",
    "    df = dataset.copy()\n",
    "    df = df[[*numeric, *categoric, target]].dropna()\n",
    "    X, y = df.drop(target, axis=1), df[target]\n",
    "    X[numeric] = X[numeric].astype(int)\n",
    "    X[categoric] = X[categoric].astype(str)\n",
    "    \n",
    "    # Only divide the dataset in training and testing *if* required. This is because synthetic\n",
    "    # datasets are of larger size, and can be split precisely for training+testing.\n",
    "    if split_to_estimate_accuracy:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify=y)\n",
    "    else:\n",
    "        X_train = X\n",
    "        y_train = y\n",
    "        # Use the real test dataset (only for real data!).\n",
    "        X_test = X_test_df\n",
    "        y_test = y_test_df\n",
    "    \n",
    "    # Apply the pipeline, and do predictions on the test set.\n",
    "    print(\"Training model...\")\n",
    "    model = pipe.fit(X_train, y_train)\n",
    "    print(\"Evaluating model...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Get predictions on the real test set.\n",
    "    y_real_est = model.predict(X_test_df).astype(str)\n",
    "\n",
    "    # Evaluate feature importance on test.\n",
    "    print(\"Evaluating feature importance...\")\n",
    "    importances = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=0, n_jobs=-1)\n",
    "    \n",
    "    # Return the model + the y_pred/y_true to evaluate + estimated importances.\n",
    "    return (y_pred, y_test, y_real_est, y_test_df, importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbccd306",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOURCE: https://rosettacode.org/wiki/Jaro_similarity#Python\n",
    "\n",
    "def jaro(s, t):\n",
    "    '''Jaro distance between two strings.'''\n",
    "    s_len = len(s)\n",
    "    t_len = len(t)\n",
    "\n",
    "    if s_len == 0 and t_len == 0:\n",
    "        return 1\n",
    "\n",
    "    match_distance = (max(s_len, t_len) // 2) - 1\n",
    "\n",
    "    s_matches = [False] * s_len\n",
    "    t_matches = [False] * t_len\n",
    "\n",
    "    matches = 0\n",
    "    transpositions = 0\n",
    "\n",
    "    for i in range(s_len):\n",
    "        start = max(0, i - match_distance)\n",
    "        end = min(i + match_distance + 1, t_len)\n",
    "\n",
    "        for j in range(start, end):\n",
    "            if t_matches[j]:\n",
    "                continue\n",
    "            if s[i] != t[j]:\n",
    "                continue\n",
    "            s_matches[i] = True\n",
    "            t_matches[j] = True\n",
    "            matches += 1\n",
    "            break\n",
    "\n",
    "    if matches == 0:\n",
    "        return 0\n",
    "\n",
    "    k = 0\n",
    "    for i in range(s_len):\n",
    "        if not s_matches[i]:\n",
    "            continue\n",
    "        while not t_matches[k]:\n",
    "            k += 1\n",
    "        if s[i] != t[k]:\n",
    "            transpositions += 1\n",
    "        k += 1\n",
    "\n",
    "    return ((matches / s_len) +\n",
    "            (matches / t_len) +\n",
    "            ((matches - transpositions / 2) / matches)) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d434d",
   "metadata": {},
   "source": [
    "### Generating tailored datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f08a14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_seed = 42387342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88c54423",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37bf62e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(master_seed)\n",
    "seeds = np.random.randint(np.iinfo(np.int16).max, size=num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c060acf6",
   "metadata": {},
   "source": [
    "IPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fe1e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    custom_ipf(teaching_file_train, columns, \"use_case_3_ipf\", seed, acceptable_marginals, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0109b17f",
   "metadata": {},
   "source": [
    "MST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bdf7a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    custom_mst(teaching_file_train, columns, \"use_case_3_mst\", seed, acceptable_marginals, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b576fb",
   "metadata": {},
   "source": [
    "### Loading synthetic datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6647bf73",
   "metadata": {},
   "source": [
    "Load generated datasets that are agnostic to the task, as well as the datasets from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a5195cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\n",
    "    \"use_case_3_ipf\",\n",
    "    \"use_case_3_mst\",\n",
    "    \"MST_eps1000\",\n",
    "    \"CTGAN_10epochs\",\n",
    "    \"PATEGAN_eps1000\",\n",
    "    \"PrivBayes_eps1000\",\n",
    "    \"SYNTHPOP\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec673c9",
   "metadata": {},
   "source": [
    "### Summarising the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf4b0b",
   "metadata": {},
   "source": [
    "Little bit of memoising: this loads results previously computed from the disk. If no such results are found, both are re-computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46b0e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"use_case_3_new.pickle\", \"rb\") as ff:\n",
    "        task_real_data, results = pickle.load(ff)\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "    # If relevant, run the task on the real data.\n",
    "    task_real_data = task(teaching_file_train, split_to_estimate_accuracy=False)\n",
    "    results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "097e0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_datasets = load_synthetic_datasets(methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ea9ef6",
   "metadata": {},
   "source": [
    "Perform the task on each dataset. This method is re-entrant: it will not recompute previously obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c87d4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f89496898c143dc9bb8a2813a87fe5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_case_3_ipf\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "use_case_3_mst\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "MST_eps1000\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "CTGAN_10epochs\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "PATEGAN_eps1000\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "PrivBayes_eps1000\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "SYNTHPOP\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Evaluating feature importance...\n"
     ]
    }
   ],
   "source": [
    "for method in tqdm.notebook.tqdm(methods):\n",
    "    # Prevent re-computation of the task.\n",
    "    if method in results and len(results[method]) == len(synthetic_datasets[method]):\n",
    "        continue\n",
    "    print(method)\n",
    "    results[method] = L = results.get(method, [])\n",
    "    for ds in synthetic_datasets[method][len(L):]:\n",
    "        L.append(task(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf7cc5",
   "metadata": {},
   "source": [
    "Save these task results to disk to remove the need for repeated expensive computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23f68062",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"use_case_3_new.pickle\", \"wb\") as ff:\n",
    "    pickle.dump((task_real_data, results), ff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8d967",
   "metadata": {},
   "source": [
    "#### Accuracy report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a31a12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy trained on _real_ data: 0.44075471698113206\n",
      "\n",
      "=== use_case_3_ipf ===\n",
      "\t Accuracy of classifier:   0.4344853005704256\n",
      "\t Accuracy estimated on SD: 0.43575921817518043\n",
      "\n",
      "=== use_case_3_mst ===\n",
      "\t Accuracy of classifier:   0.4381254936375603\n",
      "\t Accuracy estimated on SD: 0.36953438737397853\n",
      "\n",
      "=== MST_eps1000 ===\n",
      "\t Accuracy of classifier:   0.2583905221588416\n",
      "\t Accuracy estimated on SD: 0.265907495296133\n",
      "\n",
      "=== CTGAN_10epochs ===\n",
      "\t Accuracy of classifier:   0.32933742869679683\n",
      "\t Accuracy estimated on SD: 0.382936897975231\n",
      "\n",
      "=== PATEGAN_eps1000 ===\n",
      "\t Accuracy of classifier:   0.21041509433962266\n",
      "\t Accuracy estimated on SD: 0.45985003791176393\n",
      "\n",
      "=== PrivBayes_eps1000 ===\n",
      "\t Accuracy of classifier:   0.21450109697235628\n",
      "\t Accuracy estimated on SD: 0.22177118144289368\n",
      "\n",
      "=== SYNTHPOP ===\n",
      "\t Accuracy of classifier:   0.4368442299254059\n",
      "\t Accuracy estimated on SD: 0.4726277064786992\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy trained on _real_ data:\", accuracy_score(task_real_data[1], task_real_data[2]))\n",
    "print()\n",
    "\n",
    "for method in methods:\n",
    "    print('===', method, '===')\n",
    "    acc_method_real = 0\n",
    "    acc_method_est = 0\n",
    "    for task_result in results[method]:\n",
    "        y_pred, y_test, y_real_est, y_test_df, _ = task_result\n",
    "        ar = accuracy_score(y_test_df, y_real_est)\n",
    "        ae = accuracy_score(y_test, y_pred)\n",
    "        acc_method_real += ar\n",
    "        acc_method_est += ae\n",
    "    print('\\t Accuracy of classifier:  ', acc_method_real / len(results[method]))\n",
    "    print('\\t Accuracy estimated on SD:', acc_method_est / len(results[method]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5639ca4",
   "metadata": {},
   "source": [
    "#### Feature importance report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55681b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance for real model: [ 0.0377534   0.14630452  0.02841597 -0.00124616 -0.00530584  0.00362089]\n",
      "Feature ordering based on importance: [4 3 5 2 0 1]\n",
      "\n",
      "=== use_case_3_ipf ===\n",
      "\tFeature importance:     [ 0.0351223   0.14259864  0.00758741 -0.00930762 -0.01488275  0.00031102]\n",
      "\tOrdering of importance: [4 3 5 2 0 1]\n",
      "\tAverage similarity oo:  0.9777777777777779\n",
      "\n",
      "=== use_case_3_mst ===\n",
      "\tFeature importance:     [-0.00529431  0.08425904 -0.03289154 -0.06495759 -0.07246988 -0.05781361]\n",
      "\tOrdering of importance: [4 3 5 2 0 1]\n",
      "\tAverage similarity oo:  1.0\n",
      "\n",
      "=== MST_eps1000 ===\n",
      "\tFeature importance:     [ 0.00984695 -0.00254599 -0.03797228 -0.10608245 -0.08438035  0.00111362]\n",
      "\tOrdering of importance: [3 4 2 1 5 0]\n",
      "\tAverage similarity oo:  0.8333333333333334\n",
      "\n",
      "=== CTGAN_10epochs ===\n",
      "\tFeature importance:     [-0.00766927  0.02026945  0.01661897 -0.02540832 -0.03750807  0.01027296]\n",
      "\tOrdering of importance: [4 3 0 5 2 1]\n",
      "\tAverage similarity oo:  0.8922222222222222\n",
      "\n",
      "=== PATEGAN_eps1000 ===\n",
      "\tFeature importance:     [0.06005799 0.0696609  0.05601435 0.06816296 0.08241765 0.08288621]\n",
      "\tOrdering of importance: [2 0 3 1 4 5]\n",
      "\tAverage similarity oo:  0.4888888888888888\n",
      "\n",
      "=== PrivBayes_eps1000 ===\n",
      "\tFeature importance:     [-1.12428038e-02 -2.25589036e-02 -1.17447836e-02 -4.12016625e-02\n",
      " -3.40173832e-02 -9.21115448e-05]\n",
      "\tOrdering of importance: [3 4 1 2 0 5]\n",
      "\tAverage similarity oo:  0.7033333333333333\n",
      "\n",
      "=== SYNTHPOP ===\n",
      "\tFeature importance:     [0.0546199  0.1749333  0.04517313 0.02955166 0.01850614 0.02972493]\n",
      "\tOrdering of importance: [4 3 5 2 0 1]\n",
      "\tAverage similarity oo:  0.9833333333333332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importance for real model:\", task_real_data[-1][\"importances_mean\"])\n",
    "optimal_ordering = np.argsort(task_real_data[-1][\"importances_mean\"])\n",
    "print(\"Feature ordering based on importance:\", optimal_ordering)\n",
    "print()\n",
    "\n",
    "for method in methods:\n",
    "    print('===', method, '===')\n",
    "    importance = 0\n",
    "    avg_distance = 0\n",
    "    # TODO: average \n",
    "    for task_result in results[method]:\n",
    "        this_imp = task_result[-1][\"importances_mean\"]\n",
    "        this_order = np.argsort(this_imp)\n",
    "        importance += this_imp\n",
    "        avg_distance += jaro(''.join(optimal_ordering.astype(str)), ''.join(this_order.astype(str)))\n",
    "\n",
    "    print(\"\\tFeature importance:    \", importance/len(results[method]))\n",
    "    ordering = np.argsort(importance)\n",
    "    print(\"\\tOrdering of importance:\", ordering)\n",
    "    similarity = jaro(''.join(optimal_ordering.astype(str)), ''.join(ordering.astype(str)))\n",
    "#     print(\"\\tSimilarity of ordering:\", similarity)\n",
    "    print(\"\\tAverage similarity oo: \", avg_distance / len(results[method]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4c443",
   "metadata": {},
   "source": [
    "Baseline for Jaro distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44814d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "for _ in range(100000):\n",
    "    x = \"123456\"\n",
    "    y = list(x)\n",
    "    np.random.shuffle(y)\n",
    "    y2 = list(x)\n",
    "    np.random.shuffle(y2)\n",
    "    distances.append(jaro(''.join(y2), ''.join(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26e845b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6958849999999999"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
